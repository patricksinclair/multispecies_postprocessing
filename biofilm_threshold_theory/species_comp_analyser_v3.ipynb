{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pylab as pl\n",
    "from itertools import cycle\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "import collections\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRuns = 100 #reduced to 10 for now to speed things up (nRuns is the no. of files we load into the notebook)\n",
    "duration = 100.\n",
    "nSamples = 50\n",
    "\n",
    "#these durations are used for the second batch of runs, where phase_4 was run for longer to get\n",
    "#more comparative results for the plots of things vs N_bacteria\n",
    "#not used now that there's the new way of getting the time values and the runs are analysed seperately\n",
    "duration_phase2 = 100.\n",
    "nSamples_phase2 = 50\n",
    "duration_phase4 = 300.\n",
    "nSamples_phase4 = 150\n",
    "\n",
    "# phase2_filepath = \"speciesComp-phase2-fixedImm/geno_distbs\"\n",
    "# phase4_filepath = \"speciesComp-phase4-fixedImm/geno_distbs\"\n",
    "\n",
    "# phase2_bigK_filepath = \"speciesComp-phase2-fixedImm-bigK-mostPrecise/geno_distbs\"\n",
    "# phase4_bigK_filepath = \"speciesComp-phase4-fixedImm-bigK-mostPrecise/geno_distbs\"\n",
    "\n",
    "#these are for the varying immigration rate runs\n",
    "phase2_bigK_filepath = \"speciesComp-phase2-data/speciesComp-phase2-varyingImm-bigK-mostPrecise/geno_distbs\"\n",
    "phase4_bigK_filepath = \"speciesComp-phase4-data/speciesComp-phase4-varyingImm-bigK-mostPrecise/geno_distbs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfMeasurementTimes(directory_name):\n",
    "    '''\n",
    "    for each runID directory, this gets the filenames and extracts a list of the times they were sampled at.\n",
    "    directory_name is of form path_to_files/runID_<n>\n",
    "    \n",
    "    returns: sorted list of the time vals, in string form with 2 decimal places\n",
    "    '''\n",
    "    time_list = []\n",
    "    def get_numbers_from_filename(filename):\n",
    "        return re.search(r'(\\d+(?:\\.\\d+)?)', filename).group(0)\n",
    "    \n",
    "    for filename in os.listdir(directory_name):\n",
    "        time_list.append(float(get_numbers_from_filename(filename)))\n",
    "\n",
    "    return [\"{:.2f}\".format(float(t)) for t in sorted(time_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannonIndexAndEquitabilitySolo(geno_dict):\n",
    "    '''\n",
    "    This does the same as the other shannon processing stuff, but just for a single run.\n",
    "    We'll save all the individual calculations to .csv files, then combine them into a dataframe later\n",
    "    '''\n",
    "    \n",
    "    times = []\n",
    "    nBac_t = defaultdict(list) #no. of bacteria over time\n",
    "    H_t = defaultdict(list) #shannon index over time\n",
    "    E_t = defaultdict(list) #shannon equitability over time\n",
    "    S_t = defaultdict(list) #no. of species over time\n",
    "    \n",
    "    times = geno_dict.keys()\n",
    "    #print(times)\n",
    "    for time_key in times:\n",
    "\n",
    "        #here we create an array with all the genotypes in it and remove any nans\n",
    "        geno_vals = geno_dict[time_key].values.flatten()[~np.isnan(geno_dict[time_key].values.flatten())]\n",
    "        nTot = geno_vals.size #total number of bacteria in the population\n",
    "        genoCounts = collections.Counter(geno_vals) #number of members of each bacterial species in the system\n",
    "\n",
    "        H = sum([-n/nTot*math.log(n/nTot) for _, n in genoCounts.items()]) #shannon index of this run at time t\n",
    "        S = len(genoCounts.keys()) #no. of different species in the system\n",
    "        logS_adjusted = 1 if S == 1 else math.log(S)\n",
    "        E = H/logS_adjusted #shannon equitability\n",
    "\n",
    "        nBac_t[time_key].append(int(nTot))\n",
    "        H_t[time_key].append(H)\n",
    "        E_t[time_key].append(E)\n",
    "        S_t[time_key].append(S)\n",
    "        \n",
    "    #this is a very poor way of doing things, but in a rush and just trying to \n",
    "    #get a good enough job done atm\n",
    "    nBac_t_list = [b[0] for b in nBac_t.values()]\n",
    "    H_t_list = [h[0] for h in H_t.values()]\n",
    "    E_t_list = [e[0] for e in E_t.values()]\n",
    "    S_t_list = [s[0] for s in S_t.values()]\n",
    "    \n",
    "    return list(H_t.keys()), nBac_t_list, H_t_list, E_t_list, S_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannonIndexAndEquitabilitySolo_EDGE(geno_dict):\n",
    "    '''\n",
    "    This does the same as the other shannon processing stuff, but just for a single run.\n",
    "    We'll save all the individual calculations to .csv files, then combine them into a dataframe later\n",
    "    \n",
    "    This is just for the edge microhabitats\n",
    "    '''\n",
    "    \n",
    "    times = []\n",
    "    nBac_t = defaultdict(list) #no. of bacteria over time\n",
    "    H_t = defaultdict(list) #shannon index over time\n",
    "    E_t = defaultdict(list) #shannon equitability over time\n",
    "    S_t = defaultdict(list) #no. of species over time\n",
    "    \n",
    "    times = geno_dict.keys()\n",
    "    #print(times)\n",
    "    for time_key in times:\n",
    "        \n",
    "        #get the last key in this timestep, hopefully it's the edge one\n",
    "        edge_mh_key = geno_dict[time_key].keys()[-1]\n",
    "        #here we create an array with all the genotypes in it and remove any nans (this version should just be of the edge values)\n",
    "        geno_vals = geno_dict[time_key][edge_mh_key].values.flatten()[~np.isnan(geno_dict[time_key][edge_mh_key].values.flatten())]\n",
    "        nTot = geno_vals.size #total number of bacteria in the population\n",
    "        genoCounts = collections.Counter(geno_vals) #number of members of each bacterial species in the system\n",
    "\n",
    "        H = sum([-n/nTot*math.log(n/nTot) for _, n in genoCounts.items()]) #shannon index of this run at time t\n",
    "        S = len(genoCounts.keys()) #no. of different species in the system\n",
    "        logS_adjusted = 1 if S <= 1 else math.log(S)\n",
    "        E = H/logS_adjusted #shannon equitability\n",
    "\n",
    "        nBac_t[time_key].append(int(nTot))\n",
    "        H_t[time_key].append(H)\n",
    "        E_t[time_key].append(E)\n",
    "        S_t[time_key].append(S)\n",
    "        \n",
    "    #this is a very poor way of doing things, but in a rush and just trying to \n",
    "    #get a good enough job done atm\n",
    "    nBac_t_list = [b[0] for b in nBac_t.values()]\n",
    "    H_t_list = [h[0] for h in H_t.values()]\n",
    "    E_t_list = [e[0] for e in E_t.values()]\n",
    "    S_t_list = [s[0] for s in S_t.values()]\n",
    "    \n",
    "    return list(H_t.keys()), nBac_t_list, H_t_list, E_t_list, S_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeShannonCalculationsToFile(t_data, nBac_data, H_data, E_data, S_data, phase_val, filename):\n",
    "    '''\n",
    "    it takes an absolute age to load in all the genotype data, so this method will write the calculated values to a file\n",
    "    '''\n",
    "    #create a dataframe containing all the calculated values\n",
    "    #first we need a dictionary with the data in it\n",
    "    collated_data = {'t':t_data, 'nBac':nBac_data, 'H':H_data, 'E':E_data, 'S':S_data}\n",
    "    df = pd.DataFrame(collated_data)\n",
    "    df.to_csv(\"species_comp_calculations_varying_immigration/\"+phase_val+\"_data/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeShannonCalculationsToFile_EDGE(t_data, nBac_data, H_data, E_data, S_data, phase_val, filename):\n",
    "    '''\n",
    "    it takes an absolute age to load in all the genotype data, so this method will write the calculated values to a file\n",
    "    this method is just for the edge data\n",
    "    '''\n",
    "    #create a dataframe containing all the calculated values\n",
    "    #first we need a dictionary with the data in it\n",
    "    collated_data = {'t':t_data, 'nBac':nBac_data, 'H':H_data, 'E':E_data, 'S':S_data}\n",
    "    df = pd.DataFrame(collated_data)\n",
    "    df.to_csv(\"species_comp_calculations_varying_immigration/\"+phase_val+\"_data_EDGE/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGenoDistbAndProcessShannonData(directoryPath, phase_val, runID):\n",
    "    '''\n",
    "    Loading all the dataframes into one master dictionary was causing serious memory issues.\n",
    "    So here we'll just load in the geno data and process it for a single run at a time.\n",
    "    '''\n",
    "    runID_key = \"runID_\"+str(runID)\n",
    "    print(runID_key)\n",
    "    filepath_runID = directoryPath+\"/\"+runID_key\n",
    "    geno_time_dict = {} #dictionary containing geno dataframes for each timestep\n",
    "\n",
    "    time_list = getListOfMeasurementTimes(filepath_runID) #sorted list of the times that the genos were sampled at in this run\n",
    "    \n",
    "    for t in time_list:\n",
    "            \n",
    "        filepath_time = filepath_runID+\"/geno_distb-t=\"+t+\".csv\"\n",
    "\n",
    "        #need to swap the rows and columns so that the microhabitat is the key in the dataframe\n",
    "        #geno_df = pd.read_csv(filename, header=None).T\n",
    "        geno_df = pd.DataFrame([line.strip().split(',') for line in open(filepath_time, 'r')]).T\n",
    "        #geno\n",
    "        new_header = geno_df.iloc[0] #grab the first row for the header\n",
    "        geno_df = geno_df[1:] #take the data less the header row\n",
    "        geno_df.columns = new_header #set the header row as the df header\n",
    "\n",
    "        geno_df = geno_df.astype(float)\n",
    "\n",
    "        #round the time to the nearest integer value to make reading it in easier\n",
    "        #the [-3] is so the decimal point and decimal numbers are removed when casting the string to an int\n",
    "        geno_time_dict[int(t[:-3])] = geno_df\n",
    "\n",
    "    #we now have the geno distb loaded, so can process it\n",
    "    t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list = shannonIndexAndEquitabilitySolo(geno_time_dict)\n",
    "    #write the data to file \n",
    "    writeShannonCalculationsToFile(t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list, phase_val, \"shannon_calculations_precisest_bigK_\"+phase_val+\"_runID-\"+str(runID)+\".csv\")\n",
    "    del(geno_time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGenoDistbAndProcessShannonData_EDGE(directoryPath, phase_val, runID):\n",
    "    '''\n",
    "    Loading all the dataframes into one master dictionary was causing serious memory issues.\n",
    "    So here we'll just load in the geno data and process it for a single run at a time.\n",
    "    this method is just for the edge microhabitats\n",
    "    '''\n",
    "    runID_key = \"runID_\"+str(runID)\n",
    "    print(runID_key)\n",
    "    filepath_runID = directoryPath+\"/\"+runID_key\n",
    "    geno_time_dict = {} #dictionary containing geno dataframes for each timestep\n",
    "\n",
    "    time_list = getListOfMeasurementTimes(filepath_runID) #sorted list of the times that the genos were sampled at in this run\n",
    "    \n",
    "    for t in time_list:\n",
    "            \n",
    "        filepath_time = filepath_runID+\"/geno_distb-t=\"+t+\".csv\"\n",
    "\n",
    "        #need to swap the rows and columns so that the microhabitat is the key in the dataframe\n",
    "        #geno_df = pd.read_csv(filename, header=None).T\n",
    "        geno_df = pd.DataFrame([line.strip().split(',') for line in open(filepath_time, 'r')]).T\n",
    "        #geno\n",
    "        new_header = geno_df.iloc[0] #grab the first row for the header\n",
    "        geno_df = geno_df[1:] #take the data less the header row\n",
    "        geno_df.columns = new_header #set the header row as the df header\n",
    "\n",
    "        geno_df = geno_df.astype(float)\n",
    "\n",
    "        #round the time to the nearest integer value to make reading it in easier\n",
    "        #the [-3] is so the decimal point and decimal numbers are removed when casting the string to an int\n",
    "        geno_time_dict[int(t[:-3])] = geno_df\n",
    "\n",
    "    #we now have the geno distb loaded, so can process it\n",
    "    t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list = shannonIndexAndEquitabilitySolo_EDGE(geno_time_dict)\n",
    "    #write the data to file \n",
    "    writeShannonCalculationsToFile_EDGE(t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list, phase_val, \"shannon_calculations_precisest_bigK_\"+phase_val+\"_runID-\"+str(runID)+\".csv\")\n",
    "    del(geno_time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runID_14\n"
     ]
    }
   ],
   "source": [
    "readGenoDistbAndProcessShannonData(phase4_bigK_filepath, \"phase4\", 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runID_0\n",
      "runID_1\n",
      "runID_2\n",
      "runID_3\n",
      "runID_4\n",
      "runID_5\n",
      "runID_6\n",
      "runID_7\n",
      "runID_8\n",
      "runID_9\n",
      "runID_10\n",
      "runID_11\n",
      "runID_12\n",
      "runID_13\n",
      "runID_14\n",
      "runID_15\n",
      "runID_16\n",
      "runID_17\n",
      "runID_18\n",
      "runID_19\n",
      "runID_20\n",
      "runID_21\n",
      "runID_22\n",
      "runID_23\n",
      "runID_24\n",
      "runID_25\n",
      "runID_26\n",
      "runID_27\n",
      "runID_28\n",
      "runID_29\n",
      "runID_30\n",
      "runID_31\n",
      "runID_32\n",
      "runID_33\n",
      "runID_34\n",
      "runID_35\n",
      "runID_36\n",
      "runID_37\n",
      "runID_38\n",
      "runID_39\n",
      "runID_40\n",
      "runID_41\n",
      "runID_42\n",
      "runID_43\n",
      "runID_44\n",
      "runID_45\n",
      "runID_46\n",
      "runID_47\n",
      "runID_48\n",
      "runID_49\n",
      "runID_50\n",
      "runID_51\n",
      "runID_52\n",
      "runID_53\n",
      "runID_54\n",
      "runID_55\n",
      "runID_56\n",
      "runID_57\n",
      "runID_58\n",
      "runID_59\n",
      "runID_60\n",
      "runID_61\n",
      "runID_62\n",
      "runID_63\n",
      "runID_64\n",
      "runID_65\n",
      "runID_66\n",
      "runID_67\n",
      "runID_68\n",
      "runID_69\n",
      "runID_70\n",
      "runID_71\n",
      "runID_72\n",
      "runID_73\n",
      "runID_74\n",
      "runID_75\n",
      "runID_76\n",
      "runID_77\n",
      "runID_78\n",
      "runID_79\n",
      "runID_80\n",
      "runID_81\n",
      "runID_82\n",
      "runID_83\n",
      "runID_84\n",
      "runID_85\n",
      "runID_86\n",
      "runID_87\n",
      "runID_88\n",
      "runID_89\n",
      "runID_90\n",
      "runID_91\n",
      "runID_92\n",
      "runID_93\n",
      "runID_94\n",
      "runID_95\n",
      "runID_96\n",
      "runID_97\n",
      "runID_98\n",
      "runID_99\n"
     ]
    }
   ],
   "source": [
    "for runID in range(nRuns):\n",
    "    readGenoDistbAndProcessShannonData(phase2_bigK_filepath, \"phase2\", runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runID_0\n",
      "runID_1\n",
      "runID_2\n",
      "runID_3\n",
      "runID_4\n",
      "runID_5\n",
      "runID_6\n",
      "runID_7\n",
      "runID_8\n",
      "runID_9\n",
      "runID_10\n",
      "runID_11\n",
      "runID_12\n",
      "runID_13\n",
      "runID_14\n",
      "runID_15\n",
      "runID_16\n",
      "runID_17\n",
      "runID_18\n",
      "runID_19\n",
      "runID_20\n",
      "runID_21\n",
      "runID_22\n",
      "runID_23\n",
      "runID_24\n",
      "runID_25\n",
      "runID_26\n",
      "runID_27\n",
      "runID_28\n",
      "runID_29\n",
      "runID_30\n",
      "runID_31\n",
      "runID_32\n",
      "runID_33\n",
      "runID_34\n",
      "runID_35\n",
      "runID_36\n",
      "runID_37\n",
      "runID_38\n",
      "runID_39\n",
      "runID_40\n",
      "runID_41\n",
      "runID_42\n",
      "runID_43\n",
      "runID_44\n",
      "runID_45\n",
      "runID_46\n",
      "runID_47\n",
      "runID_48\n",
      "runID_49\n",
      "runID_50\n",
      "runID_51\n",
      "runID_52\n",
      "runID_53\n",
      "runID_54\n",
      "runID_55\n",
      "runID_56\n",
      "runID_57\n",
      "runID_58\n",
      "runID_59\n",
      "runID_60\n",
      "runID_61\n",
      "runID_62\n",
      "runID_63\n",
      "runID_64\n",
      "runID_65\n",
      "runID_66\n",
      "runID_67\n",
      "runID_68\n",
      "runID_69\n",
      "runID_70\n",
      "runID_71\n",
      "runID_72\n",
      "runID_73\n",
      "runID_74\n",
      "runID_75\n",
      "runID_76\n",
      "runID_77\n",
      "runID_78\n",
      "runID_79\n",
      "runID_80\n",
      "runID_81\n",
      "runID_82\n",
      "runID_83\n",
      "runID_84\n",
      "runID_85\n",
      "runID_86\n",
      "runID_87\n",
      "runID_88\n",
      "runID_89\n",
      "runID_90\n",
      "runID_91\n",
      "runID_92\n",
      "runID_93\n",
      "runID_94\n",
      "runID_95\n",
      "runID_96\n",
      "runID_97\n",
      "runID_98\n",
      "runID_99\n"
     ]
    }
   ],
   "source": [
    "for runID in range(nRuns):\n",
    "    readGenoDistbAndProcessShannonData_EDGE(phase2_bigK_filepath, \"phase2\", runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runID_75\n",
      "runID_76\n",
      "runID_77\n",
      "runID_78\n",
      "runID_79\n",
      "runID_80\n",
      "runID_81\n",
      "runID_82\n",
      "runID_83\n",
      "runID_84\n",
      "runID_85\n",
      "runID_86\n",
      "runID_87\n",
      "runID_88\n",
      "runID_89\n",
      "runID_90\n",
      "runID_91\n",
      "runID_92\n",
      "runID_93\n",
      "runID_94\n",
      "runID_95\n",
      "runID_96\n",
      "runID_97\n",
      "runID_98\n",
      "runID_99\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "run 74 had some issues, either ignore it or replace it with some other run\n",
    "maybe just have a continue statement when we iterate over the runs and get to 74\n",
    "'''\n",
    "for runID in range(75, nRuns):\n",
    "    readGenoDistbAndProcessShannonData(phase4_bigK_filepath, \"phase4\", runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runID_75\n",
      "runID_76\n",
      "runID_77\n",
      "runID_78\n",
      "runID_79\n",
      "runID_80\n",
      "runID_81\n",
      "runID_82\n",
      "runID_83\n",
      "runID_84\n",
      "runID_85\n",
      "runID_86\n",
      "runID_87\n",
      "runID_88\n",
      "runID_89\n",
      "runID_90\n",
      "runID_91\n",
      "runID_92\n",
      "runID_93\n",
      "runID_94\n",
      "runID_95\n",
      "runID_96\n",
      "runID_97\n",
      "runID_98\n",
      "runID_99\n"
     ]
    }
   ],
   "source": [
    "for runID in range(75, nRuns):\n",
    "    readGenoDistbAndProcessShannonData_EDGE(phase4_bigK_filepath, \"phase4\", runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
