{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pylab as pl\n",
    "from itertools import cycle\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "import collections\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to perform the shannon index etc calculations for the multispecies project.\n",
    "\n",
    "It's based on the code used for the shannon index etc calculations for the biofilm threshold theory species composition calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRuns = 100\n",
    "duration = 4368 #duration of sims in hours - equivalent to 26 weeks\n",
    "dates = [\"24-Sep-2020\"] #dates the simulations were performed on\n",
    "pc_res = [14, 15] #percentages of the populations which are resistant to the applied biocide\n",
    "phase2_str = \"phase2\"\n",
    "\n",
    "#parameters for the log normal distributions used\n",
    "#[scale, sigma]\n",
    "log_norm_params_14pcRes = [2.703747953786337, 0.5690825284230452]\n",
    "log_norm_params_15pcRes = [2.6133256846855746, 0.6260058161550592]\n",
    "log_norm_params_16pcRes = [2.47772924764521, 0.7060073500033884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilepathToGenoRuns(date, pc_res, phase):\n",
    "    '''\n",
    "    creates a string with the file location of the genotype distributions (all the run_ID files)\n",
    "    '''\n",
    "    \n",
    "    return \"geno_distb_data_\"+phase+\"/\"+str(pc_res)+\"_resistant-\"+date+\"/\"\n",
    "\n",
    "def getEventCountersDataframe(date, pc_res, phase, sigma, duration):\n",
    "    \n",
    "    return pd.read_csv(\"geno_distb_data_\"+phase+\"/\"+str(pc_res)+\"_resistant-\"+date+\"/\"+str(pc_res)+\"_resistant-\"+date+\"-event_counters-sigma=\"+\"{:.5f}\".format(sigma)+\"-t=\"+str(duration)+\".0.csv\")\n",
    "\n",
    "\n",
    "def getListOfMeasurementTimes(directory_name):\n",
    "    '''\n",
    "    for each runID directory, this gets the filenames and extracts a list of the times they were sampled at.\n",
    "    directory_name is of form path_to_files/runID_<n>\n",
    "    \n",
    "    returns: sorted list of the time vals, in string form with 2 decimal places\n",
    "    '''\n",
    "    time_list = []\n",
    "    def get_numbers_from_filename(filename):\n",
    "        return re.search(r'(\\d+(?:\\.\\d+)?)', filename).group(0)\n",
    "    \n",
    "    for filename in os.listdir(directory_name):\n",
    "        time_list.append(float(get_numbers_from_filename(filename)))\n",
    "\n",
    "    return [\"{:.2f}\".format(float(t)) for t in sorted(time_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannonIndexAndEquitabilitySolo(geno_dict):\n",
    "    '''\n",
    "    For a single run, this calculates the shannon variables H, E, S.\n",
    "    Outputs a .csv file with the calculated variables over time.\n",
    "    Can then combine these into a dictionary of dataframes later.\n",
    "    '''\n",
    "    \n",
    "    times = []\n",
    "    nBac_t = defaultdict(list) #no. of bacteria over time\n",
    "    H_t = defaultdict(list) #shannon index over time\n",
    "    E_t = defaultdict(list) #shannon equitability over time\n",
    "    S_t = defaultdict(list) #no. of species over time\n",
    "    \n",
    "    times = geno_dict.keys()\n",
    "    #print(times)\n",
    "    for time_key in times:\n",
    "\n",
    "        #here we create an array with all the genotypes in it and remove any nans\n",
    "        geno_vals = geno_dict[time_key].values.flatten()[~np.isnan(geno_dict[time_key].values.flatten())]\n",
    "        nTot = geno_vals.size #total number of bacteria in the population\n",
    "        genoCounts = collections.Counter(geno_vals) #number of members of each bacterial species in the system\n",
    "\n",
    "        H = sum([-n/nTot*math.log(n/nTot) for _, n in genoCounts.items()]) #shannon index of this run at time t\n",
    "        S = len(genoCounts.keys()) #no. of different species in the system\n",
    "        logS_adjusted = 1 if S == 1 else math.log(S)\n",
    "        E = H/logS_adjusted #shannon equitability\n",
    "\n",
    "        nBac_t[time_key].append(int(nTot))\n",
    "        H_t[time_key].append(H)\n",
    "        E_t[time_key].append(E)\n",
    "        S_t[time_key].append(S)\n",
    "        \n",
    "    #this is a very poor way of doing things, but in a rush and just trying to \n",
    "    #get a good enough job done atm\n",
    "    nBac_t_list = [b[0] for b in nBac_t.values()]\n",
    "    H_t_list = [h[0] for h in H_t.values()]\n",
    "    E_t_list = [e[0] for e in E_t.values()]\n",
    "    S_t_list = [s[0] for s in S_t.values()]\n",
    "    \n",
    "    return list(H_t.keys()), nBac_t_list, H_t_list, E_t_list, S_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannonIndexAndEquitabilitySolo_EDGE(geno_dict):\n",
    "    '''\n",
    "    This does the same as the other shannon processing stuff, but just for a single run.\n",
    "    We'll save all the individual calculations to .csv files, then combine them into a dataframe later\n",
    "    \n",
    "    This is just for the edge microhabitats\n",
    "    '''\n",
    "    \n",
    "    times = []\n",
    "    nBac_t = defaultdict(list) #no. of bacteria over time\n",
    "    H_t = defaultdict(list) #shannon index over time\n",
    "    E_t = defaultdict(list) #shannon equitability over time\n",
    "    S_t = defaultdict(list) #no. of species over time\n",
    "    \n",
    "    times = geno_dict.keys()\n",
    "    #print(times)\n",
    "    for time_key in times:\n",
    "        \n",
    "        #get the last key in this timestep, hopefully it's the edge one\n",
    "        edge_mh_key = geno_dict[time_key].keys()[-1]\n",
    "        #here we create an array with all the genotypes in it and remove any nans (this version should just be of the edge values)\n",
    "        geno_vals = geno_dict[time_key][edge_mh_key].values.flatten()[~np.isnan(geno_dict[time_key][edge_mh_key].values.flatten())]\n",
    "        nTot = geno_vals.size #total number of bacteria in the population\n",
    "        genoCounts = collections.Counter(geno_vals) #number of members of each bacterial species in the system\n",
    "\n",
    "        H = sum([-n/nTot*math.log(n/nTot) for _, n in genoCounts.items()]) #shannon index of this run at time t\n",
    "        S = len(genoCounts.keys()) #no. of different species in the system\n",
    "        logS_adjusted = 1 if S <= 1 else math.log(S)\n",
    "        E = H/logS_adjusted #shannon equitability\n",
    "\n",
    "        nBac_t[time_key].append(int(nTot))\n",
    "        H_t[time_key].append(H)\n",
    "        E_t[time_key].append(E)\n",
    "        S_t[time_key].append(S)\n",
    "        \n",
    "    #this is a very poor way of doing things, but in a rush and just trying to \n",
    "    #get a good enough job done atm\n",
    "    nBac_t_list = [b[0] for b in nBac_t.values()]\n",
    "    H_t_list = [h[0] for h in H_t.values()]\n",
    "    E_t_list = [e[0] for e in E_t.values()]\n",
    "    S_t_list = [s[0] for s in S_t.values()]\n",
    "    \n",
    "    return list(H_t.keys()), nBac_t_list, H_t_list, E_t_list, S_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeShannonCalculationsToFile(t_data, nBac_data, H_data, E_data, S_data, pc_res, date, phase_val, growth_val, filename):\n",
    "    '''\n",
    "    it takes an absolute age to load in all the genotype data, so this method will write the calculated values to a file\n",
    "    '''\n",
    "    #create a dataframe containing all the calculated values\n",
    "    #first we need a dictionary with the data in it\n",
    "    collated_data = {'t':t_data, 'nBac':nBac_data, 'H':H_data, 'E':E_data, 'S':S_data}\n",
    "    df = pd.DataFrame(collated_data)\n",
    "    df.to_csv(\"shannon_calculations_\"+phase_val+\"_\"+growth_val+\"/\"+str(pc_res)+\"_pc_res-\"+date+\"/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeShannonCalculationsToFile_EDGE(t_data, nBac_data, H_data, E_data, S_data, pc_res, date, phase_val, growth_val, filename):\n",
    "    '''\n",
    "    it takes an absolute age to load in all the genotype data, so this method will write the calculated values to a file\n",
    "    this method is just for the edge data\n",
    "    '''\n",
    "    #create a dataframe containing all the calculated values\n",
    "    #first we need a dictionary with the data in it\n",
    "    collated_data = {'t':t_data, 'nBac':nBac_data, 'H':H_data, 'E':E_data, 'S':S_data}\n",
    "    df = pd.DataFrame(collated_data)\n",
    "    df.to_csv(\"shannon_calculations_\"+phase_val+\"_\"+growth_val+\"_EDGE/\"+str(pc_res)+\"_pc_res-\"+date+\"_\"+str(growth_val)+\"_EDGE/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGenoDistbAndProcessShannonData(directoryPath, pc_res, date, phase_val, growth_val, runID):\n",
    "    '''\n",
    "    This loads in all the genotype data for a single run.\n",
    "    \n",
    "    growth_val can either be \"GROWTH\" for runs which exhibit growth, \"NOGROWTH\" for runs which remain in the first microhabitat,\n",
    "    or \"\" if you want to \n",
    "    '''\n",
    "    runID_key = \"runID_\"+str(runID)\n",
    "    print(runID_key)\n",
    "    filepath_runID = directoryPath+\"/\"+runID_key\n",
    "    geno_time_dict = {} #dictionary containing geno dataframes for each timestep\n",
    "\n",
    "    time_list = getListOfMeasurementTimes(filepath_runID) #sorted list of the times that the genos were sampled at in this run\n",
    "    \n",
    "    for t in time_list:\n",
    "            \n",
    "        filepath_time = filepath_runID+\"/geno_distb-t=\"+t+\".csv\"\n",
    "\n",
    "        #need to swap the rows and columns so that the microhabitat is the key in the dataframe\n",
    "        #geno_df = pd.read_csv(filename, header=None).T\n",
    "        geno_df = pd.DataFrame([line.strip().split(',') for line in open(filepath_time, 'r')]).T\n",
    "        #geno\n",
    "        new_header = geno_df.iloc[0] #grab the first row for the header\n",
    "        geno_df = geno_df[1:] #take the data less the header row\n",
    "        geno_df.columns = new_header #set the header row as the df header\n",
    "\n",
    "        geno_df = geno_df.astype(float)\n",
    "\n",
    "        #round the time to the nearest integer value to make reading it in easier\n",
    "        #the [-3] is so the decimal point and decimal numbers are removed when casting the string to an int\n",
    "        geno_time_dict[int(t[:-3])] = geno_df\n",
    "\n",
    "    #we now have the geno distb loaded, so can process it\n",
    "    t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list = shannonIndexAndEquitabilitySolo(geno_time_dict)\n",
    "    #write the data to file \n",
    "    writeShannonCalculationsToFile(t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list, pc_res=pc_res, date=date, phase_val=phase_val, growth_val=growth_val,\n",
    "                                   filename=\"shannon_calculations-\"+str(pc_res)+\"_pc_res-runID_\"+str(runID)+\".csv\")\n",
    "    del(geno_time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGenoDistbAndProcessShannonData_EDGE(directoryPath, pc_res, date, phase_val, growth_val, runID):\n",
    "    '''\n",
    "    Loading all the dataframes into one master dictionary was causing serious memory issues.\n",
    "    So here we'll just load in the geno data and process it for a single run at a time.\n",
    "    this method is just for the edge microhabitats\n",
    "    '''\n",
    "    runID_key = \"runID_\"+str(runID)\n",
    "    print(runID_key)\n",
    "    filepath_runID = directoryPath+\"/\"+runID_key\n",
    "    geno_time_dict = {} #dictionary containing geno dataframes for each timestep\n",
    "\n",
    "    time_list = getListOfMeasurementTimes(filepath_runID) #sorted list of the times that the genos were sampled at in this run\n",
    "    \n",
    "    for t in time_list:\n",
    "            \n",
    "        filepath_time = filepath_runID+\"/geno_distb-t=\"+t+\".csv\"\n",
    "\n",
    "        #need to swap the rows and columns so that the microhabitat is the key in the dataframe\n",
    "        #geno_df = pd.read_csv(filename, header=None).T\n",
    "        geno_df = pd.DataFrame([line.strip().split(',') for line in open(filepath_time, 'r')]).T\n",
    "        #geno\n",
    "        new_header = geno_df.iloc[0] #grab the first row for the header\n",
    "        geno_df = geno_df[1:] #take the data less the header row\n",
    "        geno_df.columns = new_header #set the header row as the df header\n",
    "\n",
    "        geno_df = geno_df.astype(float)\n",
    "\n",
    "        #round the time to the nearest integer value to make reading it in easier\n",
    "        #the [-3] is so the decimal point and decimal numbers are removed when casting the string to an int\n",
    "        geno_time_dict[int(t[:-3])] = geno_df\n",
    "\n",
    "    #we now have the geno distb loaded, so can process it\n",
    "    t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list = shannonIndexAndEquitabilitySolo_EDGE(geno_time_dict)\n",
    "    #write the data to file \n",
    "    writeShannonCalculationsToFile_EDGE(t_list, nBac_list, H_vs_t_list, E_vs_t_list, S_vs_t_list, pc_res=pc_res, date=date, phase_val=phase_val, growth_val=growth_val,\n",
    "                                   filename=\"shannon_calculations-\"+str(pc_res)+\"_pc_res-runID_\"+str(runID)+\".csv\")\n",
    "    del(geno_time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geno_distb_data_phase2/14_resistant-24-Sep-2020/\n"
     ]
    }
   ],
   "source": [
    "pc_res_14_24_Sep_filepath = getFilepathToGenoRuns(date=dates[0], pc_res=pc_res[0], phase=phase2_str)\n",
    "pc_res_15_24_Sep_filepath = getFilepathToGenoRuns(date=dates[0], pc_res=pc_res[1], phase=phase2_str)\n",
    "print(pc_res_14_24_Sep_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discrepancy in species composition for runs which exhibit growth, and runs which don't, I believe is throwing off the shannon calculations somewhat.\n",
    "\n",
    "Therefore, using the event_counters dataframe, we can seperate the runs into categories of GROWTH (thickess > 0) and NO_GROWTH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_counters_14pc_24Sep = getEventCountersDataframe(dates[0], pc_res[0], phase2_str, log_norm_params_14pcRes[1], duration)\n",
    "event_counters_15pc_24Sep = getEventCountersDataframe(dates[0], pc_res[1], phase2_str, log_norm_params_15pcRes[1], duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROWTH_RUNS_14pc_24Sep = list(event_counters_14pc_24Sep[\"runID\"][(event_counters_14pc_24Sep[\"bf_thickness\"] > 0)])\n",
    "GROWTH_RUNS_15pc_24Sep = list(event_counters_15pc_24Sep[\"runID\"][(event_counters_15pc_24Sep[\"bf_thickness\"] > 0)])\n",
    "\n",
    "NOGROWTH_RUNS_14pc_24Sep = list(event_counters_14pc_24Sep[\"runID\"][~(event_counters_14pc_24Sep[\"bf_thickness\"] > 0)])\n",
    "NOGROWTH_RUNS_15pc_24Sep = list(event_counters_15pc_24Sep[\"runID\"][~(event_counters_15pc_24Sep[\"bf_thickness\"] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runID_17\n",
      "runID_38\n",
      "runID_48\n",
      "runID_49\n",
      "runID_66\n",
      "runID_79\n"
     ]
    }
   ],
   "source": [
    "for runID in GROWTH_RUNS_14pc_24Sep:\n",
    "    readGenoDistbAndProcessShannonData_EDGE(directoryPath=pc_res_14_24_Sep_filepath, pc_res=pc_res[0], date=dates[0], phase_val=phase2_str, growth_val=\"GROWTH\", runID=runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runID_37\n",
      "runID_47\n",
      "runID_49\n",
      "runID_56\n",
      "runID_57\n",
      "runID_62\n",
      "runID_70\n",
      "runID_77\n",
      "runID_83\n",
      "runID_84\n",
      "runID_89\n",
      "runID_91\n",
      "runID_94\n"
     ]
    }
   ],
   "source": [
    "for runID in GROWTH_RUNS_15pc_24Sep:\n",
    "    readGenoDistbAndProcessShannonData_EDGE(directoryPath=pc_res_15_24_Sep_filepath, pc_res=pc_res[1], date=dates[0], phase_val=phase2_str, growth_val=\"GROWTH\", runID=runID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
